{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second step of fitting -- Using `OpenCV` to fit the patches of defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mingrenshen/Projects/multitype-defect-detection'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results Path\n",
    "import os\n",
    "# Import packages\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fitting Algorithm Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitEllipse(rawPath, outPath, imgFile):\n",
    "    \"\"\"\n",
    "    This function fits the ellipse on the cropped patches of the defects\n",
    "    and save the fitting ellipse in \"imgFile\"+\"_fitted.jpg\" as the vistualization of final results\n",
    "    \n",
    "    rawPath :: the path of the result cropped images\n",
    "    imgFile :: the file name of the small patch of the detected defects\n",
    "    \n",
    "    Return :\n",
    "    ellipse : Typical Ouput of OpenCV's ellipse function : \n",
    "        center\tCenter of the ellipse.\n",
    "        axes\tHalf of the size of the ellipse main axes.\n",
    "        angle\tEllipse rotation angle in degrees.\n",
    "\n",
    "        ( (center_rr, center_cc), (minor_axe, major_axe), angle )\n",
    "    \n",
    "    \"\"\"\n",
    "    img = cv2.imread(rawPath+imgFile)\n",
    "    imgName = imgFile.rstrip(\".jpg\")\n",
    "    #plt.imshow(img)\n",
    "    #img = cv2.medianBlur(img, 25)\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #ret, thresh = cv2.threshold(gray,50,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C)\n",
    "    #thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,23,2)\n",
    "    # Otsu's thresholding after Gaussian filtering\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    blur_gray = cv2.GaussianBlur(gray,(3,3),0)\n",
    "    ret3,thresh = cv2.threshold(blur_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # noise removal\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)) #np.ones((5,5),np.uint8) #\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 3)\n",
    "    #closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    #opening = closing\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "    cv2.imwrite(outPath + imgName+'_sureBG.jpg', sure_bg)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,1,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.2*dist_transform.max(),255,0)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    markers = cv2.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]\n",
    "    imgray = sure_fg #cv2.cvtColor(sure_fg,cv2.COLOR_BGR2GRAY)\n",
    "    #ret,thresh = cv2.threshold(imgray,50,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C)\n",
    "    #thresh = cv2.adaptiveThreshold(imgray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,23,2)\n",
    "    ret3,thresh = cv2.threshold(imgray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    im,contours,hierarchy= cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_index = 0\n",
    "    # if contour length is more than 1\n",
    "    if len(contours) == 0:\n",
    "        print(\"error in contour calculation\")\n",
    "    elif len(contours) == 1:\n",
    "        contoursALL = contours[0]\n",
    "    else:\n",
    "        indexDict = dict()\n",
    "        for idx,con in enumerate(contours):\n",
    "            indexDict[cv2.contourArea(con)] = idx\n",
    "        # print(indexDict)\n",
    "        A = sorted(indexDict.keys(),reverse=True)\n",
    "        # print(A)\n",
    "        max_index = indexDict[A[0]]\n",
    "        contoursALL = contours[indexDict[A[1]]]\n",
    "        for i in range(len(contours)):\n",
    "            if i != max_index and i != indexDict[A[1]] :\n",
    "                #print(contours[i])\n",
    "                tmp = contours[i]\n",
    "                contoursALL = np.concatenate((contoursALL,tmp))\n",
    "    cnt = contoursALL\n",
    "    ellipse = cv2.fitEllipse(cnt)\n",
    "    #print(ellipse)\n",
    "    imgNN = cv2.imread(rawPath+imgFile)\n",
    "    #cv2.imwrite(outPath+imgName+'_fitted11.jpg', imgNN)\n",
    "    cv2.ellipse(imgNN,ellipse,(0,255,0),3)\n",
    "    cv2.imwrite(outPath+imgName+'_fitted.jpg', imgNN)\n",
    "    #plt.imshow(img)\n",
    "    return ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.jpg\n",
      "49.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "14.jpg\n",
      "28.jpg\n",
      "29.jpg\n",
      "15.jpg\n",
      "17.jpg\n",
      "16.jpg\n",
      "12.jpg\n",
      "13.jpg\n",
      "39.jpg\n",
      "11.jpg\n",
      "10.jpg\n",
      "38.jpg\n",
      "21.jpg\n",
      "35.jpg\n",
      "34.jpg\n",
      "20.jpg\n",
      "36.jpg\n",
      "22.jpg\n",
      "23.jpg\n",
      "37.jpg\n",
      "33.jpg\n",
      "27.jpg\n",
      "26.jpg\n",
      "32.jpg\n",
      "18.jpg\n",
      "24.jpg\n",
      "30.jpg\n",
      "31.jpg\n",
      "25.jpg\n",
      "19.jpg\n",
      "42.jpg\n",
      "4.jpg\n",
      "56.jpg\n",
      "5.jpg\n",
      "57.jpg\n",
      "43.jpg\n",
      "55.jpg\n",
      "7.jpg\n",
      "41.jpg\n",
      "40.jpg\n",
      "54.jpg\n",
      "6.jpg\n",
      "2.jpg\n",
      "50.jpg\n",
      "44.jpg\n",
      "45.jpg\n",
      "3.jpg\n",
      "51.jpg\n",
      "47.jpg\n",
      "53.jpg\n",
      "1.jpg\n",
      "52.jpg\n",
      "0.jpg\n",
      "46.jpg\n"
     ]
    }
   ],
   "source": [
    "# Path of Raw Results for testing single image fitting\n",
    "rawPath = \"./RawResult0p1/7/\"\n",
    "outPath = \"./outputFitting0p1/\"\n",
    "for f in os.listdir(rawPath):\n",
    "    if f != '.DS_Store':\n",
    "        print(f)\n",
    "        fitEllipse(rawPath,outPath,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Fitting Pipeline\n",
    "\n",
    "**Input** \n",
    "1. `pix2nm` : records down the pixel to nm information of each image\n",
    "2. `rawPrediction` : the folder generated by `RawPredictionGeneration.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Converstion Factor\n",
    "# all following the rules that \n",
    "# 0 for 111\n",
    "# 1 for black dot\n",
    "# 2 for 100\n",
    "\n",
    "# pix2nm is the dict that stores all the coefficient to convert pixel value to real nm data\n",
    "# The format is { 'img_name' :  [pixelNum,nmNum]}\n",
    "# in total the full name of all 12 testing images should be here\n",
    "# pix2nm is the dict that stores all the coefficient to convert pixel value to real nm data\n",
    "# The format is { 'img_name' :  [pixelNum,nmNum]}\n",
    "# in total the full name of all 12 testing images should be here\n",
    "pix2nm = {'0501_300kx_1nm_clhaadf3_0010.jpg' : [1024, 490],\n",
    "          '0501_300kx_1nm_clhaadf3_0014.jpg' : [1024, 490],\n",
    "          '1ROI_100kx_4100CL_foil1.jpg' : [1024, 890],\n",
    "          '200kV_500kx_p2nm_8cmCL_grain1_0056 - Copy.jpg' : [1024, 290], #[1024, 291.248],\n",
    "          '200kV_500kx_p2nm_8cmCL_grain2_0036.jpg' : [1024, 490],#[1024, 485.413],\n",
    "          '5401_300kx_1nm_clhaadf3_0020.jpg' : [1024, 490],\n",
    "          '8ROI_100kx_4100CL_foil1.jpg' : [1024, 890],\n",
    "          'BF X500K, 06 (2).jpg' : [1024, 145],\n",
    "          'g1_backonzone_GBtowardsfrom_0007.jpg' : [2048, 290], #[2048, 291.248],\n",
    "          'g2_midonzone_GBtowardsfront_0010.jpg' : [2048, 290], #[2048, 291.248],\n",
    "          'grid1_roi1_500kx_0p5nm_haadf1_0025.jpg' : [1024, 290],\n",
    "          'grid1_roi2_500kx_0p5nm_haadf1_0047.jpg': [1024, 290]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': 'grid1_roi2_500kx_0p5nm_haadf1_0047', '10': 'grid1_roi1_500kx_0p5nm_haadf1_0025', '1': '0501_300kx_1nm_clhaadf3_0014', '0': '0501_300kx_1nm_clhaadf3_0010', '3': '200kV_500kx_p2nm_8cmCL_grain1_0056 - Copy', '2': '1ROI_100kx_4100CL_foil1', '5': '5401_300kx_1nm_clhaadf3_0020', '4': '200kV_500kx_p2nm_8cmCL_grain2_0036', '7': 'BF X500K, 06 (2)', '6': '8ROI_100kx_4100CL_foil1', '9': 'g2_midonzone_GBtowardsfront_0010', '8': 'g1_backonzone_GBtowardsfrom_0007'}\n"
     ]
    }
   ],
   "source": [
    "# OverAll Fitting for all images\n",
    "rawPath = \"./RawResult0p05/\"\n",
    "outPath = \"./outputFitting0p05/\"\n",
    "# In Total we have 12 testing images so first read in the `log.txt` to gain the imgName to testID information\n",
    "testID2imgName = {}\n",
    "with open(rawPath+'log.txt') as flog:\n",
    "    for line in flog.readlines():\n",
    "        numID, fname = line.split(' , ')\n",
    "        testID2imgName[numID.strip()] = fname.strip()\n",
    "print(testID2imgName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReff(ra,rb,cls):\n",
    "    '''\n",
    "    return the effective radius of defects based on the class, major and minor axes\n",
    "    \n",
    "    ra : major axes full length\n",
    "    rb : minor axes full length\n",
    "    cls : class of the defects\n",
    "    \n",
    "    return\n",
    "    reff : the effective radius of defects\n",
    "    \n",
    "    '''\n",
    "    if cls == 0 or cls == 2:\n",
    "        # Reff should be half of 2a\n",
    "        reff = ra * 0.5\n",
    "    else:\n",
    "        # this is due to reff = sqrt(2a * 2b * 0.25)\n",
    "        reff = np.sqrt(0.25 * ra * rb)\n",
    "    return reff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# read in all csv files with pandas dataframe\n",
    "for imgID in range(12):\n",
    "    print(imgID)\n",
    "    imgRawInfo = pd.read_csv(rawPath + 'results_' + str(imgID) + '.csv')\n",
    "    # check the number of defects patches matchs the number of defects recorded in csv\n",
    "    totalPatchNum = 0\n",
    "    for f in os.listdir(rawPath + str(imgID)):\n",
    "        if f.endswith(\".jpg\"):\n",
    "            totalPatchNum += 1\n",
    "    # if number of patchs mismatchs the records in csv `assert` will report an error\n",
    "    assert(totalPatchNum == imgRawInfo.shape[0])\n",
    "    # create the output Path to store all the results\n",
    "    try:\n",
    "        os.mkdir(str(outPath + str(imgID)))\n",
    "    except OSError:\n",
    "        print(\"Creation of the directory is failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatchRatio(rawPath, imgFile):\n",
    "    \"\"\"\n",
    "    This function fits the size of the patch of defects\n",
    "    \n",
    "    rawPath :: the path of the result cropped images\n",
    "    imgFile :: the file name of the small patch of the detected defects\n",
    "    \n",
    "    Return :\n",
    "    patch_size : (width_x, hight_y)\n",
    "    \n",
    "    \"\"\"\n",
    "    img = cv2.imread(rawPath+imgFile)\n",
    "    height, width, channels = img.shape\n",
    "    return (width,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This part of code will \n",
    "    * calculate all the needed information of the fitted ellipse\n",
    "    * store them in a new csv\n",
    "\n",
    "Typical Ouput of OpenCV's ellipse function : \n",
    "    center\tCenter of the ellipse.\n",
    "    axes\tHalf of the size of the ellipse main axes.\n",
    "    angle\tEllipse rotation angle in degrees.\n",
    "    \n",
    "    ( (center_rr, center_cc), (minor_axe, major_axe), angle )\n",
    "    \n",
    "Then transform them into two types of information\n",
    "(1) Geo information -- effective radius (nm)\n",
    "(2) Population information -- area density (# * m^-2)\n",
    "\n",
    "'''\n",
    "# Then Fitted Each Patch into Ellipse\n",
    "# Path of Raw Results for testing single image fitting\n",
    "# Using another loop to do fitting\n",
    "for imgID in range(12):\n",
    "    print(imgID)\n",
    "    imgRawInfo = pd.read_csv(rawPath + 'results_' + str(imgID) + '.csv')\n",
    "    totalPathchNum = imgRawInfo.shape[0]\n",
    "    # Pixel to nm factor\n",
    "    scaleFactor = pix2nm[testID2imgName[str(imgID)]+\".jpg\"]\n",
    "    #print(scaleFactor)\n",
    "    rawFolder = rawPath + str(imgID)+\"/\"\n",
    "    outFolder = outPath + str(imgID)+\"/\"\n",
    "    \n",
    "    for index,row in imgRawInfo.iterrows():\n",
    "        defect_patch_name = str(index)+\".jpg\"\n",
    "        ellipseInfo = fitEllipse(rawFolder,outFolder,defect_patch_name)\n",
    "        patchInfo = getPatchRatio(rawFolder,defect_patch_name)\n",
    "        # (width,height) for pathchInfo\n",
    "        patchConvertToOringialRatio = ( (imgRawInfo.loc[index,'Xmax'] - imgRawInfo.loc[index,'Xmin'])/(1.0*patchInfo[0]),\n",
    "                                         (imgRawInfo.loc[index,'Ymax'] - imgRawInfo.loc[index,'Ymin'])/(1.0*patchInfo[1]))\n",
    "        #print(patchConvertToOringialRatio)\n",
    "        avgRatio = 0.5 * (patchConvertToOringialRatio[0] + patchConvertToOringialRatio[1])\n",
    "        # center_x\n",
    "        imgRawInfo.loc[index,'center_x'] = ellipseInfo[0][0] * avgRatio\n",
    "        # center_y\n",
    "        imgRawInfo.loc[index,'center_y'] = ellipseInfo[0][1] * avgRatio\n",
    "        # center_x_real\n",
    "        imgRawInfo.loc[index,'center_x_real'] = imgRawInfo.loc[index,'center_x']  + imgRawInfo.loc[index,'Xmin']\n",
    "        # center_y_real\n",
    "        imgRawInfo.loc[index,'center_y_real'] = imgRawInfo.loc[index,'center_y'] + imgRawInfo.loc[index,'Ymin']\n",
    "        # minor axes\n",
    "        imgRawInfo.loc[index,'minor_axe'] = ellipseInfo[1][0] * avgRatio\n",
    "        # major axes\n",
    "        imgRawInfo.loc[index,'major_axe'] = ellipseInfo[1][1] * avgRatio\n",
    "        # Reff_pixel\n",
    "        imgRawInfo.loc[index,'Reff_pixel'] = getReff(imgRawInfo.loc[index,'major_axe'], \\\n",
    "                                                     imgRawInfo.loc[index,'minor_axe'], \\\n",
    "                                                     imgRawInfo.loc[index,'class'])\n",
    "        # Reff_nm\n",
    "        imgRawInfo.loc[index,'Reff_nm'] = imgRawInfo.loc[index,'Reff_pixel'] * scaleFactor[1] / scaleFactor[0]\n",
    "        # RotAngle_degree\n",
    "        imgRawInfo.loc[index,'RotAngle_degree'] = ellipseInfo[2]\n",
    "        # RotAngle_radian\n",
    "        imgRawInfo.loc[index,'RotAngle_radian'] = ellipseInfo[2] * np.pi /180.0\n",
    "    imgRawInfo.to_csv (outPath + 'results_' + str(imgID) + '.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
